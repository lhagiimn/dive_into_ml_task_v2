{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ7S6jYZbh-_"
   },
   "source": [
    "# Problem 1 Sharing and executing the official tutorial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "HjX61o35eDp7",
    "outputId": "be39169a-1a76-4229-f793-3353aa36a4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Keun Ho Ryu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUHCb0er5gSL",
    "outputId": "85f50fc2-f74b-4292-fe6e-7f15e80e4cfa"
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UOwYjk2Z5hR1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Keun Ho Ryu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                             tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                             tf.keras.layers.Dropout(0.2),\n",
    "                             tf.keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iE9mVVun6ddv",
    "outputId": "9c829526-0123-4bef-dab8-95518ace107d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01732822,  0.09751379,  0.43244794, -0.49461657, -0.06304891,\n",
       "         0.5951032 , -1.0284455 , -0.49546194, -0.8981193 ,  0.2024337 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not trained model \n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrBHLljc6z0y",
    "outputId": "51638e14-21a6-4b0d-a6d6-bcb6399b3bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10575148, 0.11458048, 0.16016613, 0.06337993, 0.09758412,\n",
       "        0.18845645, 0.03716317, 0.06332637, 0.04233628, 0.12725559]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax\n",
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xIPZ7uZs64P9"
   },
   "outputs": [],
   "source": [
    "# loss function \n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjz1Jwfe65ln",
    "outputId": "c80d3ba8-5036-4a96-fe1b-77d471d9689b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6688883"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss debug\n",
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "--3dVaSn68Mv"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=loss_fn,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vd0Otg4M7Emc",
    "outputId": "345e805d-e0a8-4949-acd9-e36f1d2e39fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2993 - accuracy: 0.9131\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1454 - accuracy: 0.9575\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1059 - accuracy: 0.9675\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0879 - accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0762 - accuracy: 0.9761\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0652 - accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0590 - accuracy: 0.9814\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0526 - accuracy: 0.9835\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0494 - accuracy: 0.9838\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0428 - accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e9b625c0d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqcr_MrW76F9",
    "outputId": "67899a25-1dbc-475d-bb4e-89cf4208335f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0725 - accuracy: 0.9814 - 949ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07250611484050751, 0.9814000129699707]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.998, 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.002]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_test[4:5]).numpy()\n",
    "np.round(tf.nn.softmax(predictions).numpy().astype(\"float32\"), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "J85CoNhZ8J_v"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AsIviRt8LX6",
    "outputId": "05c6002d-924b-427e-bfca-7789731a85a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ,\n",
       "        0.   ],\n",
       "       [0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   ],\n",
       "       [0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   ],\n",
       "       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.998, 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.002]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(probability_model(x_test[:5]).numpy(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Problem 2] (Advance assignment) Execute various methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqoiSosyeEJz"
   },
   "source": [
    "# [Problem 3] Learning Iris (binary classification) with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dxJDlRDq8WZb"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "\n",
    "#Condition extraction from data frame\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "# NumPy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# Convert label to number\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y = y.astype(np.int64)[:, np.newaxis]\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "DecFBDXKFI70"
   },
   "outputs": [],
   "source": [
    "# data scaling \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qN0KPZQLFN15"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "-jNKC1L69q_B"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation='relu', input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DblegAy6Atiu",
    "outputId": "4b0c7093-44ab-433d-db37-19ad7b2573ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 50)                250       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5451 (21.29 KB)\n",
      "Trainable params: 5451 (21.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "jfGj40H9_r1B"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gSVvsUEABAY",
    "outputId": "5aba36ea-a8fe-4c0c-97c4-643846f1366d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 - 2s - loss: 0.5690 - accuracy: 0.7188 - val_loss: 0.2374 - val_accuracy: 1.0000 - 2s/epoch - 453ms/step\n",
      "Epoch 2/20\n",
      "4/4 - 0s - loss: 0.2600 - accuracy: 0.9219 - val_loss: 0.0751 - val_accuracy: 1.0000 - 101ms/epoch - 25ms/step\n",
      "Epoch 3/20\n",
      "4/4 - 0s - loss: 0.1216 - accuracy: 0.9688 - val_loss: 0.0312 - val_accuracy: 1.0000 - 78ms/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "4/4 - 0s - loss: 0.0837 - accuracy: 0.9531 - val_loss: 0.0208 - val_accuracy: 1.0000 - 122ms/epoch - 30ms/step\n",
      "Epoch 5/20\n",
      "4/4 - 0s - loss: 0.0560 - accuracy: 0.9688 - val_loss: 0.0233 - val_accuracy: 1.0000 - 91ms/epoch - 23ms/step\n",
      "Epoch 6/20\n",
      "4/4 - 0s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 1.0000 - 90ms/epoch - 22ms/step\n",
      "Epoch 7/20\n",
      "4/4 - 0s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 1.0000 - 87ms/epoch - 22ms/step\n",
      "Epoch 8/20\n",
      "4/4 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000 - 81ms/epoch - 20ms/step\n",
      "Epoch 9/20\n",
      "4/4 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000 - 81ms/epoch - 20ms/step\n",
      "Epoch 10/20\n",
      "4/4 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000 - 115ms/epoch - 29ms/step\n",
      "Epoch 11/20\n",
      "4/4 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000 - 85ms/epoch - 21ms/step\n",
      "Epoch 12/20\n",
      "4/4 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000 - 94ms/epoch - 23ms/step\n",
      "Epoch 13/20\n",
      "4/4 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000 - 98ms/epoch - 24ms/step\n",
      "Epoch 14/20\n",
      "4/4 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000 - 71ms/epoch - 18ms/step\n",
      "Epoch 15/20\n",
      "4/4 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000 - 99ms/epoch - 25ms/step\n",
      "Epoch 16/20\n",
      "4/4 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000 - 89ms/epoch - 22ms/step\n",
      "Epoch 17/20\n",
      "4/4 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000 - 110ms/epoch - 27ms/step\n",
      "Epoch 18/20\n",
      "4/4 - 0s - loss: 8.3364e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000 - 134ms/epoch - 33ms/step\n",
      "Epoch 19/20\n",
      "4/4 - 0s - loss: 7.5048e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000 - 182ms/epoch - 45ms/step\n",
      "Epoch 20/20\n",
      "4/4 - 0s - loss: 6.6351e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000 - 153ms/epoch - 38ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3aL9gyTDnnm",
    "outputId": "e9054562-0fe0-4622-a722-78118a94d26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0006272855098359287\n",
      "Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "908TLT0QEJ0X"
   },
   "source": [
    "# [Problem 4] Learn Iris (multi-level classification) with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Q7mUJb0ZEJSL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "\n",
    "#Condition extraction from data frame\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X).astype(np.float32)\n",
    "\n",
    "# Convert label to number\n",
    "y[y == \"Iris-setosa\"] = 0\n",
    "y[y == \"Iris-versicolor\"] = 1\n",
    "y[y == \"Iris-virginica\"] = 2\n",
    "\n",
    "# One Hot encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "TsacqbB_EUiL"
   },
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zAL5TiyWFyRe"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "CYyScKjVEelU"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(n_input))\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kr04YroTEelU",
    "outputId": "e393473d-21ee-4298-928e-220d28f33542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 50)                250       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5653 (22.08 KB)\n",
      "Trainable params: 5653 (22.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "2ePkkoqXEelV"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFYDoIYDEelV",
    "outputId": "894e448b-aaae-474e-843f-98bde8c27adb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 - 2s - loss: 0.8325 - accuracy: 0.6771 - val_loss: 0.4885 - val_accuracy: 0.7917 - 2s/epoch - 391ms/step\n",
      "Epoch 2/20\n",
      "5/5 - 0s - loss: 0.3588 - accuracy: 0.8958 - val_loss: 0.3484 - val_accuracy: 0.7917 - 161ms/epoch - 32ms/step\n",
      "Epoch 3/20\n",
      "5/5 - 0s - loss: 0.2384 - accuracy: 0.9167 - val_loss: 0.3750 - val_accuracy: 0.7917 - 122ms/epoch - 24ms/step\n",
      "Epoch 4/20\n",
      "5/5 - 0s - loss: 0.1607 - accuracy: 0.9375 - val_loss: 0.3564 - val_accuracy: 0.7917 - 147ms/epoch - 29ms/step\n",
      "Epoch 5/20\n",
      "5/5 - 0s - loss: 0.1135 - accuracy: 0.9688 - val_loss: 0.3507 - val_accuracy: 0.7917 - 120ms/epoch - 24ms/step\n",
      "Epoch 6/20\n",
      "5/5 - 0s - loss: 0.0938 - accuracy: 0.9583 - val_loss: 0.3490 - val_accuracy: 0.8333 - 153ms/epoch - 31ms/step\n",
      "Epoch 7/20\n",
      "5/5 - 0s - loss: 0.0712 - accuracy: 0.9792 - val_loss: 0.3664 - val_accuracy: 0.8750 - 116ms/epoch - 23ms/step\n",
      "Epoch 8/20\n",
      "5/5 - 0s - loss: 0.0618 - accuracy: 0.9896 - val_loss: 0.2500 - val_accuracy: 0.9167 - 166ms/epoch - 33ms/step\n",
      "Epoch 9/20\n",
      "5/5 - 0s - loss: 0.0579 - accuracy: 0.9583 - val_loss: 0.2898 - val_accuracy: 0.9167 - 155ms/epoch - 31ms/step\n",
      "Epoch 10/20\n",
      "5/5 - 0s - loss: 0.0435 - accuracy: 0.9792 - val_loss: 0.2638 - val_accuracy: 0.9167 - 185ms/epoch - 37ms/step\n",
      "Epoch 11/20\n",
      "5/5 - 0s - loss: 0.0515 - accuracy: 0.9792 - val_loss: 0.2510 - val_accuracy: 0.9167 - 339ms/epoch - 68ms/step\n",
      "Epoch 12/20\n",
      "5/5 - 0s - loss: 0.0527 - accuracy: 0.9792 - val_loss: 0.3698 - val_accuracy: 0.9167 - 219ms/epoch - 44ms/step\n",
      "Epoch 13/20\n",
      "5/5 - 0s - loss: 0.0358 - accuracy: 0.9792 - val_loss: 0.2808 - val_accuracy: 0.9167 - 185ms/epoch - 37ms/step\n",
      "Epoch 14/20\n",
      "5/5 - 0s - loss: 0.0387 - accuracy: 0.9792 - val_loss: 0.2935 - val_accuracy: 0.9167 - 242ms/epoch - 48ms/step\n",
      "Epoch 15/20\n",
      "5/5 - 0s - loss: 0.0363 - accuracy: 0.9688 - val_loss: 0.2665 - val_accuracy: 0.9167 - 363ms/epoch - 73ms/step\n",
      "Epoch 16/20\n",
      "5/5 - 0s - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.3450 - val_accuracy: 0.9167 - 158ms/epoch - 32ms/step\n",
      "Epoch 17/20\n",
      "5/5 - 0s - loss: 0.0228 - accuracy: 0.9896 - val_loss: 0.2209 - val_accuracy: 0.9167 - 218ms/epoch - 44ms/step\n",
      "Epoch 18/20\n",
      "5/5 - 0s - loss: 0.0388 - accuracy: 0.9792 - val_loss: 0.2997 - val_accuracy: 0.9167 - 173ms/epoch - 35ms/step\n",
      "Epoch 19/20\n",
      "5/5 - 0s - loss: 0.0623 - accuracy: 0.9688 - val_loss: 0.3417 - val_accuracy: 0.9167 - 112ms/epoch - 22ms/step\n",
      "Epoch 20/20\n",
      "5/5 - 0s - loss: 0.0458 - accuracy: 0.9792 - val_loss: 0.1942 - val_accuracy: 0.9167 - 347ms/epoch - 69ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_KkfvKQEelV",
    "outputId": "806af85f-ed06-40ae-af71-50cb520b43a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04934503510594368\n",
      "Train accuracy: 0.9791666865348816\n",
      "Test loss: 0.020072953775525093\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMHm1IKjGbuc"
   },
   "source": [
    "# [Problem 5] Learning House Prices with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "gouVHoQFGXz2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/house_price/train.csv\")\n",
    "#Condition extraction from data frame\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = np.log(np.array(y).reshape(-1, 1))\n",
    "X = np.array(X).astype(np.float32)\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jv3CW9w5GslQ"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Eyf0MYNKG8G9"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(n_input))\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lscfs4vzG8G-",
    "outputId": "c62f72ac-9c99-4490-c45d-b20ad2993994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 50)                150       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5553 (21.69 KB)\n",
      "Trainable params: 5553 (21.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "YANUinfEG8G-"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.optimizers.Adagrad(learning_rate=0.005),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ViA4lvyHG8G-",
    "outputId": "859c2cfa-e900-4fa8-f254-f490872923fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 - 1s - loss: 2491.1143 - mse: 2491.1143 - val_loss: 20.2119 - val_mse: 20.2119 - 889ms/epoch - 19ms/step\n",
      "Epoch 2/20\n",
      "47/47 - 0s - loss: 15.2790 - mse: 15.2790 - val_loss: 9.7095 - val_mse: 9.7095 - 181ms/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "47/47 - 0s - loss: 6.0870 - mse: 6.0870 - val_loss: 6.7372 - val_mse: 6.7372 - 216ms/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "47/47 - 0s - loss: 3.8510 - mse: 3.8510 - val_loss: 3.0592 - val_mse: 3.0592 - 179ms/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "47/47 - 0s - loss: 2.8142 - mse: 2.8142 - val_loss: 2.1521 - val_mse: 2.1521 - 202ms/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "47/47 - 1s - loss: 1.9753 - mse: 1.9753 - val_loss: 2.3786 - val_mse: 2.3786 - 631ms/epoch - 13ms/step\n",
      "Epoch 7/20\n",
      "47/47 - 0s - loss: 1.4771 - mse: 1.4771 - val_loss: 1.2814 - val_mse: 1.2814 - 250ms/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "47/47 - 0s - loss: 1.2470 - mse: 1.2470 - val_loss: 1.3441 - val_mse: 1.3441 - 209ms/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "47/47 - 0s - loss: 0.9712 - mse: 0.9712 - val_loss: 1.1021 - val_mse: 1.1021 - 214ms/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "47/47 - 0s - loss: 0.9112 - mse: 0.9112 - val_loss: 0.9756 - val_mse: 0.9756 - 192ms/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "47/47 - 0s - loss: 0.7371 - mse: 0.7371 - val_loss: 0.7046 - val_mse: 0.7046 - 185ms/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "47/47 - 0s - loss: 0.7696 - mse: 0.7696 - val_loss: 0.6214 - val_mse: 0.6214 - 202ms/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "47/47 - 0s - loss: 0.6176 - mse: 0.6176 - val_loss: 0.6180 - val_mse: 0.6180 - 191ms/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "47/47 - 0s - loss: 0.5779 - mse: 0.5779 - val_loss: 0.5750 - val_mse: 0.5750 - 184ms/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "47/47 - 0s - loss: 0.5418 - mse: 0.5418 - val_loss: 0.7137 - val_mse: 0.7137 - 193ms/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "47/47 - 0s - loss: 0.5331 - mse: 0.5331 - val_loss: 0.5009 - val_mse: 0.5009 - 217ms/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "47/47 - 0s - loss: 0.5249 - mse: 0.5249 - val_loss: 0.4827 - val_mse: 0.4827 - 343ms/epoch - 7ms/step\n",
      "Epoch 18/20\n",
      "47/47 - 0s - loss: 0.4870 - mse: 0.4870 - val_loss: 0.6896 - val_mse: 0.6896 - 252ms/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "47/47 - 0s - loss: 0.5061 - mse: 0.5061 - val_loss: 0.4924 - val_mse: 0.4924 - 206ms/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "47/47 - 0s - loss: 0.4354 - mse: 0.4354 - val_loss: 0.4414 - val_mse: 0.4414 - 206ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f25f98jG8G-",
    "outputId": "e27d40fe-c036-4692-f024-0f2fb1687a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.40809664130210876\n",
      "Train mse: 0.40809664130210876\n",
      "Test loss: 0.8928992748260498\n",
      "Test mse: 0.8928992748260498\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train mse:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test mse:', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV5uJn99ILmd"
   },
   "source": [
    "# [Problem 6] Learning MNIST with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ODYZeFQ3t65C"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vrzmqf26t932",
    "outputId": "957b1158-7e98-4c09-f919-3eb31670c7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(y_train.shape) # (10000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(y_test.shape)\n",
    "print(X_train[0].dtype) # uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "o7Vfb9qTuOaf",
    "outputId": "fb9c65f1-6330-4a16-9726-faaca2cfd7fd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgiklEQVR4nO3de3BU9fnH8c9yyXJLFsIlIVwDCKjcpggpIggSCdFSQLRotQPVQaHBKijYOApaL1FUVBSFOpaICgozAsp0sAoktAo43GTQkgKNBSQBAbOBAAGS7+8P6v5cCcIJG54kvF8z35nsOd9nz8PhkA9n9+xZn3POCQCAi6yGdQMAgEsTAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBhEtSZmamfD6fvvnmG8+1AwYMUJcuXSLaT9u2bTVmzJiIPidQ2RFAQDXVtm1b+Xy+M8a4ceOsWwMkSbWsGwBQcXr06KEHHnggbFnHjh2NugHCEUBANdaiRQvdcccd1m0AZeIlOOB/li5dqhtvvFEJCQny+/1q3769nnjiCZWUlJQ5f8OGDbr66qtVt25dJSYmavbs2WfMKS4u1rRp09ShQwf5/X61atVKU6ZMUXFxcbl6zMvL07Zt23Ty5Mnzrjlx4oSKiorKtT2gIhFAwP9kZmaqQYMGmjRpkl5++WX17NlTU6dO1Z/+9Kcz5n7//fe64YYb1LNnT02fPl0tW7bU+PHj9de//jU0p7S0VL/+9a/1/PPPa+jQoXrllVc0fPhwvfjiixo1alS5ekxPT9fll1+ub7/99rzmr1y5UvXq1VODBg3Utm1bvfzyy+XaLlAhHHAJmjt3rpPkcnNzQ8uOHj16xrx77rnH1atXzx0/fjy07Nprr3WS3AsvvBBaVlxc7Hr06OGaNWvmTpw44Zxz7u2333Y1atRw//jHP8Kec/bs2U6S++yzz0LL2rRp40aPHn3OvkePHn1G32czdOhQ9+yzz7olS5a4N9980/Xr189JclOmTDlnLXAxcAYE/E/dunVDPx8+fFgHDhxQv379dPToUW3bti1sbq1atXTPPfeEHkdFRemee+7R/v37tWHDBknSokWLdPnll6tz5846cOBAaFx33XWSpFWrVnnuMTMzU845tW3b9pxzP/zwQ02ZMkXDhg3TnXfeqezsbKWkpGjGjBnas2eP520DkUYAAf/z1VdfacSIEQoEAoqJiVHTpk1Db+AHg8GwuQkJCapfv37Ysh+uLvvhs0Xbt2/XV199paZNm4aNH+bt37+/gv9E4Xw+nyZOnKhTp04pKyvrom4bKAtXwQGSCgoKdO211yomJkZ//vOf1b59e9WpU0cbN27UQw89pNLSUs/PWVpaqq5du2rGjBllrm/VqtWFtu3ZD9s8dOjQRd828FMEECApKytLBw8e1AcffKD+/fuHlufm5pY5f+/evSoqKgo7C/r3v/8tSaGXx9q3b68vv/xSgwYNks/nq7jmPfjPf/4jSWratKlxJwAvwQGSpJo1a0qSnHOhZSdOnNBrr71W5vxTp05pzpw5YXPnzJmjpk2bqmfPnpKk3/zmN/r222/1xhtvnFF/7Nixcl0afb6XYR86dOiMy8dPnjypZ555RlFRURo4cKDnbQORxhkQIOnqq69Wo0aNNHr0aP3xj3+Uz+fT22+/HRZIP5aQkKBnn31W33zzjTp27Kj3339fmzdv1l/+8hfVrl1bkvS73/1OCxcu1Lhx47Rq1Sr17dtXJSUl2rZtmxYuXKiPP/5YV111lac+09PT9dZbbyk3N/dnL0T48MMP9eSTT+rmm29WYmKiDh06pPnz52vr1q16+umnFR8f72m7QEUggABJjRs31rJly/TAAw/okUceUaNGjXTHHXdo0KBBSklJOWN+o0aN9NZbb+nee+/VG2+8obi4OL366qsaO3ZsaE6NGjW0ZMkSvfjii5o3b54WL16sevXqqV27drrvvvsq9JY4Xbt21RVXXKF33nlH3333naKiotSjRw8tXLhQt9xyS4VtF/DC5872XzwAACoQ7wEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABOV7nNApaWl2rt3r6KjoyvN7UsAAOfPOafDhw8rISFBNWqc/Tyn0gXQ3r17TW7SCACIrN27d6tly5ZnXV/pXoKLjo62bgEAEAHn+n1eYQE0a9YstW3bVnXq1FFSUpK++OKL86rjZTcAqB7O9fu8QgLo/fff16RJkzRt2jRt3LhR3bt3V0pKykX/Ai4AQCVWEd/z3bt3b5eWlhZ6XFJS4hISElxGRsY5a4PBoJPEYDAYjCo+gsHgz/6+j/gZ0IkTJ7RhwwYlJyeHltWoUUPJyclas2bNGfOLi4tVWFgYNgAA1V/EA+jAgQMqKSlRXFxc2PK4uDjl5+efMT8jI0OBQCA0uAIOAC4N5lfBpaenKxgMhsbu3butWwIAXAQR/xxQkyZNVLNmTe3bty9s+b59+8r8Fka/3y+/3x/pNgAAlVzEz4CioqLUs2dPrVixIrSstLRUK1asUJ8+fSK9OQBAFVUhd0KYNGmSRo8erauuukq9e/fWSy+9pKKiIv3+97+viM0BAKqgCgmgUaNG6bvvvtPUqVOVn5+vHj16aPny5WdcmAAAuHT5nHPOuokfKywsVCAQsG4DAHCBgsGgYmJizrre/Co4AMCliQACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJWtYNAJVJzZo1PdcEAoEK6CQyJkyYUK66evXqea7p1KmT55q0tDTPNc8//7znmttuu81zjSQdP37cc80zzzzjuebxxx/3XFMdcAYEADBBAAEATEQ8gB577DH5fL6w0blz50hvBgBQxVXIe0BXXnmlPv300//fSC3eagIAhKuQZKhVq5bi4+Mr4qkBANVEhbwHtH37diUkJKhdu3a6/fbbtWvXrrPOLS4uVmFhYdgAAFR/EQ+gpKQkZWZmavny5Xr99deVm5urfv366fDhw2XOz8jIUCAQCI1WrVpFuiUAQCUU8QBKTU3VLbfcom7duiklJUV/+9vfVFBQoIULF5Y5Pz09XcFgMDR2794d6ZYAAJVQhV8d0LBhQ3Xs2FE7duwoc73f75ff76/oNgAAlUyFfw7oyJEj2rlzp5o3b17RmwIAVCERD6AHH3xQ2dnZ+uabb/T5559rxIgRqlmzZrlvhQEAqJ4i/hLcnj17dNttt+ngwYNq2rSprrnmGq1du1ZNmzaN9KYAAFVYxAPovffei/RTopJq3bq155qoqCjPNVdffbXnmmuuucZzjXT6PUuvRo4cWa5tVTd79uzxXDNz5kzPNSNGjPBcc7arcM/lyy+/9FyTnZ1drm1dirgXHADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM+55yzbuLHCgsLFQgErNu4pPTo0aNcdStXrvRcw99t1VBaWuq55s477/Rcc+TIEc815ZGXl1euuu+//95zTU5OTrm2VR0Fg0HFxMScdT1nQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE7WsG4C9Xbt2lavu4MGDnmu4G/Zp69at81xTUFDguWbgwIGeayTpxIkTnmvefvvtcm0Lly7OgAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJjgZqTQoUOHylU3efJkzzW/+tWvPNds2rTJc83MmTM915TX5s2bPddcf/31nmuKioo811x55ZWeayTpvvvuK1cd4AVnQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEz4nHPOuokfKywsVCAQsG4DFSQmJsZzzeHDhz3XzJkzx3ONJN11112ea+644w7PNQsWLPBcA1Q1wWDwZ//NcwYEADBBAAEATHgOoNWrV2vo0KFKSEiQz+fTkiVLwtY75zR16lQ1b95cdevWVXJysrZv3x6pfgEA1YTnACoqKlL37t01a9asMtdPnz5dM2fO1OzZs7Vu3TrVr19fKSkpOn78+AU3CwCoPjx/I2pqaqpSU1PLXOec00svvaRHHnlEw4YNkyTNmzdPcXFxWrJkiW699dYL6xYAUG1E9D2g3Nxc5efnKzk5ObQsEAgoKSlJa9asKbOmuLhYhYWFYQMAUP1FNIDy8/MlSXFxcWHL4+LiQut+KiMjQ4FAIDRatWoVyZYAAJWU+VVw6enpCgaDobF7927rlgAAF0FEAyg+Pl6StG/fvrDl+/btC637Kb/fr5iYmLABAKj+IhpAiYmJio+P14oVK0LLCgsLtW7dOvXp0yeSmwIAVHGer4I7cuSIduzYEXqcm5urzZs3KzY2Vq1bt9b999+vJ598UpdddpkSExP16KOPKiEhQcOHD49k3wCAKs5zAK1fv14DBw4MPZ40aZIkafTo0crMzNSUKVNUVFSku+++WwUFBbrmmmu0fPly1alTJ3JdAwCqPG5GimrpueeeK1fdD/+h8iI7O9tzzY8/qnC+SktLPdcAlrgZKQCgUiKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOBu2KiW6tevX666jz76yHPNtdde67kmNTXVc83f//53zzWAJe6GDQColAggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJjgZqTAj7Rv395zzcaNGz3XFBQUeK5ZtWqV55r169d7rpGkWbNmea6pZL9KUAlwM1IAQKVEAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABDcjBS7QiBEjPNfMnTvXc010dLTnmvJ6+OGHPdfMmzfPc01eXp7nGlQd3IwUAFApEUAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMHNSAEDXbp08VwzY8YMzzWDBg3yXFNec+bM8Vzz1FNPea759ttvPdfABjcjBQBUSgQQAMCE5wBavXq1hg4dqoSEBPl8Pi1ZsiRs/ZgxY+Tz+cLGkCFDItUvAKCa8BxARUVF6t69u2bNmnXWOUOGDFFeXl5oLFiw4IKaBABUP7W8FqSmpio1NfVn5/j9fsXHx5e7KQBA9Vch7wFlZWWpWbNm6tSpk8aPH6+DBw+edW5xcbEKCwvDBgCg+ot4AA0ZMkTz5s3TihUr9Oyzzyo7O1upqakqKSkpc35GRoYCgUBotGrVKtItAQAqIc8vwZ3LrbfeGvq5a9eu6tatm9q3b6+srKwyP5OQnp6uSZMmhR4XFhYSQgBwCajwy7DbtWunJk2aaMeOHWWu9/v9iomJCRsAgOqvwgNoz549OnjwoJo3b17RmwIAVCGeX4I7cuRI2NlMbm6uNm/erNjYWMXGxurxxx/XyJEjFR8fr507d2rKlCnq0KGDUlJSIto4AKBq8xxA69ev18CBA0OPf3j/ZvTo0Xr99de1ZcsWvfXWWyooKFBCQoIGDx6sJ554Qn6/P3JdAwCqPG5GClQRDRs29FwzdOjQcm1r7ty5nmt8Pp/nmpUrV3quuf766z3XwAY3IwUAVEoEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPcDRvAGYqLiz3X1Krl+dtddOrUKc815flusaysLM81uHDcDRsAUCkRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw4f3ugQAuWLdu3TzX3HzzzZ5revXq5blGKt+NRcvj66+/9lyzevXqCugEFjgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIKbkQI/0qlTJ881EyZM8Fxz0003ea6Jj4/3XHMxlZSUeK7Jy8vzXFNaWuq5BpUTZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMcDNSVHrluQnnbbfdVq5tlefGom3bti3Xtiqz9evXe6556qmnPNd8+OGHnmtQfXAGBAAwQQABAEx4CqCMjAz16tVL0dHRatasmYYPH66cnJywOcePH1daWpoaN26sBg0aaOTIkdq3b19EmwYAVH2eAig7O1tpaWlau3atPvnkE508eVKDBw9WUVFRaM7EiRP10UcfadGiRcrOztbevXvL9eVbAIDqzdNFCMuXLw97nJmZqWbNmmnDhg3q37+/gsGg3nzzTc2fP1/XXXedJGnu3Lm6/PLLtXbtWv3yl7+MXOcAgCrtgt4DCgaDkqTY2FhJ0oYNG3Ty5EklJyeH5nTu3FmtW7fWmjVrynyO4uJiFRYWhg0AQPVX7gAqLS3V/fffr759+6pLly6SpPz8fEVFRalhw4Zhc+Pi4pSfn1/m82RkZCgQCIRGq1atytsSAKAKKXcApaWlaevWrXrvvfcuqIH09HQFg8HQ2L179wU9HwCgaijXB1EnTJigZcuWafXq1WrZsmVoeXx8vE6cOKGCgoKws6B9+/ad9cOEfr9ffr+/PG0AAKowT2dAzjlNmDBBixcv1sqVK5WYmBi2vmfPnqpdu7ZWrFgRWpaTk6Ndu3apT58+kekYAFAteDoDSktL0/z587V06VJFR0eH3tcJBAKqW7euAoGA7rrrLk2aNEmxsbGKiYnRvffeqz59+nAFHAAgjKcAev311yVJAwYMCFs+d+5cjRkzRpL04osvqkaNGho5cqSKi4uVkpKi1157LSLNAgCqD59zzlk38WOFhYUKBALWbeA8xMXFea654oorPNe8+uqrnms6d+7suaayW7duneea5557rlzbWrp0qeea0tLScm0L1VcwGFRMTMxZ13MvOACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiXJ9Iyoqr9jYWM81c+bMKde2evTo4bmmXbt25dpWZfb55597rnnhhRc813z88ceea44dO+a5BrhYOAMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggpuRXiRJSUmeayZPnuy5pnfv3p5rWrRo4bmmsjt69Gi56mbOnOm55umnn/ZcU1RU5LkGqG44AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCm5FeJCNGjLgoNRfT119/7blm2bJlnmtOnTrlueaFF17wXCNJBQUF5aoD4B1nQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEz4nHPOuokfKywsVCAQsG4DAHCBgsGgYmJizrqeMyAAgAkCCABgwlMAZWRkqFevXoqOjlazZs00fPhw5eTkhM0ZMGCAfD5f2Bg3blxEmwYAVH2eAig7O1tpaWlau3atPvnkE508eVKDBw9WUVFR2LyxY8cqLy8vNKZPnx7RpgEAVZ+nb0Rdvnx52OPMzEw1a9ZMGzZsUP/+/UPL69Wrp/j4+Mh0CAColi7oPaBgMChJio2NDVv+7rvvqkmTJurSpYvS09N19OjRsz5HcXGxCgsLwwYA4BLgyqmkpMTdeOONrm/fvmHL58yZ45YvX+62bNni3nnnHdeiRQs3YsSIsz7PtGnTnCQGg8FgVLMRDAZ/NkfKHUDjxo1zbdq0cbt37/7ZeStWrHCS3I4dO8pcf/z4cRcMBkNj9+7d5juNwWAwGBc+zhVAnt4D+sGECRO0bNkyrV69Wi1btvzZuUlJSZKkHTt2qH379mes9/v98vv95WkDAFCFeQog55zuvfdeLV68WFlZWUpMTDxnzebNmyVJzZs3L1eDAIDqyVMApaWlaf78+Vq6dKmio6OVn58vSQoEAqpbt6527typ+fPn64YbblDjxo21ZcsWTZw4Uf3791e3bt0q5A8AAKiivLzvo7O8zjd37lznnHO7du1y/fv3d7Gxsc7v97sOHTq4yZMnn/N1wB8LBoPmr1syGAwG48LHuX73czNSAECF4GakAIBKiQACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgotIFkHPOugUAQASc6/d5pQugw4cPW7cAAIiAc/0+97lKdspRWlqqvXv3Kjo6Wj6fL2xdYWGhWrVqpd27dysmJsaoQ3vsh9PYD6exH05jP5xWGfaDc06HDx9WQkKCatQ4+3lOrYvY03mpUaOGWrZs+bNzYmJiLukD7Afsh9PYD6exH05jP5xmvR8CgcA551S6l+AAAJcGAggAYKJKBZDf79e0adPk9/utWzHFfjiN/XAa++E09sNpVWk/VLqLEAAAl4YqdQYEAKg+CCAAgAkCCABgggACAJgggAAAJqpMAM2aNUtt27ZVnTp1lJSUpC+++MK6pYvusccek8/nCxudO3e2bqvCrV69WkOHDlVCQoJ8Pp+WLFkStt45p6lTp6p58+aqW7eukpOTtX37dptmK9C59sOYMWPOOD6GDBli02wFycjIUK9evRQdHa1mzZpp+PDhysnJCZtz/PhxpaWlqXHjxmrQoIFGjhypffv2GXVcMc5nPwwYMOCM42HcuHFGHZetSgTQ+++/r0mTJmnatGnauHGjunfvrpSUFO3fv9+6tYvuyiuvVF5eXmj885//tG6pwhUVFal79+6aNWtWmeunT5+umTNnavbs2Vq3bp3q16+vlJQUHT9+/CJ3WrHOtR8kaciQIWHHx4IFCy5ihxUvOztbaWlpWrt2rT755BOdPHlSgwcPVlFRUWjOxIkT9dFHH2nRokXKzs7W3r17ddNNNxl2HXnnsx8kaezYsWHHw/Tp0406PgtXBfTu3dulpaWFHpeUlLiEhASXkZFh2NXFN23aNNe9e3frNkxJcosXLw49Li0tdfHx8e65554LLSsoKHB+v98tWLDAoMOL46f7wTnnRo8e7YYNG2bSj5X9+/c7SS47O9s5d/rvvnbt2m7RokWhOf/617+cJLdmzRqrNivcT/eDc85de+217r777rNr6jxU+jOgEydOaMOGDUpOTg4tq1GjhpKTk7VmzRrDzmxs375dCQkJateunW6//Xbt2rXLuiVTubm5ys/PDzs+AoGAkpKSLsnjIysrS82aNVOnTp00fvx4HTx40LqlChUMBiVJsbGxkqQNGzbo5MmTYcdD586d1bp162p9PPx0P/zg3XffVZMmTdSlSxelp6fr6NGjFu2dVaW7G/ZPHThwQCUlJYqLiwtbHhcXp23bthl1ZSMpKUmZmZnq1KmT8vLy9Pjjj6tfv37aunWroqOjrdszkZ+fL0llHh8/rLtUDBkyRDfddJMSExO1c+dOPfzww0pNTdWaNWtUs2ZN6/YirrS0VPfff7/69u2rLl26SDp9PERFRalhw4Zhc6vz8VDWfpCk3/72t2rTpo0SEhK0ZcsWPfTQQ8rJydEHH3xg2G24Sh9A+H+pqamhn7t166akpCS1adNGCxcu1F133WXYGSqDW2+9NfRz165d1a1bN7Vv315ZWVkaNGiQYWcVIy0tTVu3br0k3gf9OWfbD3fffXfo565du6p58+YaNGiQdu7cqfbt21/sNstU6V+Ca9KkiWrWrHnGVSz79u1TfHy8UVeVQ8OGDdWxY0ft2LHDuhUzPxwDHB9nateunZo0aVItj48JEyZo2bJlWrVqVdj3h8XHx+vEiRMqKCgIm19dj4ez7YeyJCUlSVKlOh4qfQBFRUWpZ8+eWrFiRWhZaWmpVqxYoT59+hh2Zu/IkSPauXOnmjdvbt2KmcTERMXHx4cdH4WFhVq3bt0lf3zs2bNHBw8erFbHh3NOEyZM0OLFi7Vy5UolJiaGre/Zs6dq164ddjzk5ORo165d1ep4ONd+KMvmzZslqXIdD9ZXQZyP9957z/n9fpeZmem+/vprd/fdd7uGDRu6/Px869YuqgceeMBlZWW53Nxc99lnn7nk5GTXpEkTt3//fuvWKtThw4fdpk2b3KZNm5wkN2PGDLdp0yb33//+1znn3DPPPOMaNmzoli5d6rZs2eKGDRvmEhMT3bFjx4w7j6yf2w+HDx92Dz74oFuzZo3Lzc11n376qfvFL37hLrvsMnf8+HHr1iNm/PjxLhAIuKysLJeXlxcaR48eDc0ZN26ca926tVu5cqVbv36969Onj+vTp49h15F3rv2wY8cO9+c//9mtX7/e5ebmuqVLl7p27dq5/v37G3cerkoEkHPOvfLKK65169YuKirK9e7d261du9a6pYtu1KhRrnnz5i4qKsq1aNHCjRo1yu3YscO6rQq3atUqJ+mMMXr0aOfc6UuxH330URcXF+f8fr8bNGiQy8nJsW26Avzcfjh69KgbPHiwa9q0qatdu7Zr06aNGzt2bLX7T1pZf35Jbu7cuaE5x44dc3/4wx9co0aNXL169dyIESNcXl6eXdMV4Fz7YdeuXa5///4uNjbW+f1+16FDBzd58mQXDAZtG/8Jvg8IAGCi0r8HBACongggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABg4v8AdMucyrqBf0QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "nBKGgl49M5Rw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipclmDklcKWm",
    "outputId": "e24c5e93-1b74-4302-d957-5e954d9e24ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis]).toarray()\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis]).toarray()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "jp3ph50sIcnE"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3TFPQ4CIfb-"
   },
   "source": [
    "**Model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "ms1Wxy4YIcnE"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(n_input))\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajvGS2vMIcnF",
    "outputId": "3e6f817e-ba5a-44dc-8dd1-a8bd32b20f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 50)                39250     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45360 (177.19 KB)\n",
      "Trainable params: 45360 (177.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "xKANuaJcIcnF"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vuAv5z9PIcnF",
    "outputId": "8dfa7927-7156-4e01-a84c-737e7cef8bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.2848 - accuracy: 0.9164 - val_loss: 0.1625 - val_accuracy: 0.9524\n",
      "Epoch 2/10\n",
      "2400/2400 [==============================] - 14s 6ms/step - loss: 0.1356 - accuracy: 0.9585 - val_loss: 0.1395 - val_accuracy: 0.9561\n",
      "Epoch 3/10\n",
      "2400/2400 [==============================] - 17s 7ms/step - loss: 0.0995 - accuracy: 0.9691 - val_loss: 0.1174 - val_accuracy: 0.9636\n",
      "Epoch 4/10\n",
      "2400/2400 [==============================] - 18s 8ms/step - loss: 0.0814 - accuracy: 0.9740 - val_loss: 0.1115 - val_accuracy: 0.9666\n",
      "Epoch 5/10\n",
      "2400/2400 [==============================] - 11s 4ms/step - loss: 0.0668 - accuracy: 0.9779 - val_loss: 0.1069 - val_accuracy: 0.9690\n",
      "Epoch 6/10\n",
      "2400/2400 [==============================] - 11s 5ms/step - loss: 0.0547 - accuracy: 0.9824 - val_loss: 0.1107 - val_accuracy: 0.9697\n",
      "Epoch 7/10\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.0470 - accuracy: 0.9845 - val_loss: 0.1108 - val_accuracy: 0.9703\n",
      "Epoch 8/10\n",
      "2400/2400 [==============================] - 13s 6ms/step - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.1077 - val_accuracy: 0.9713\n",
      "Epoch 9/10\n",
      "2400/2400 [==============================] - 12s 5ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.1180 - val_accuracy: 0.9722\n",
      "Epoch 10/10\n",
      "2400/2400 [==============================] - 22s 9ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.1260 - val_accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFCBnVm3IcnF",
    "outputId": "442f2767-330e-4409-9525-8d804769dd38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02445949986577034\n",
      "Train accuracy: 0.991812527179718\n",
      "Test loss: 0.10069000720977783\n",
      "Test accuracy: 0.9731000065803528\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test_one_hot, verbose = 0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Problem 7] (Advance assignment) Rewriting to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification: Iris Dataset on Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\keun ho ryu\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "\n",
    "#Condition extraction from data frame\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "# NumPy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# Convert label to number\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y = y.astype(np.int64)[:, np.newaxis]\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "\n",
    "    def __init__(self, x, y, shuffle=True, batch_size=16):\n",
    "        \n",
    "        self.X = x\n",
    "        self.y = y.astype(\"float32\")\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.n_conts = self.X.shape[1]\n",
    "        self.len = self.X.shape[0]\n",
    "        n_batches, remainder = divmod(self.len, self.batch_size)\n",
    "\n",
    "        if remainder > 0:\n",
    "            n_batches += 1\n",
    "        self.n_batches = n_batches\n",
    "        self.remainder = remainder  # for debugging\n",
    "\n",
    "        self.idxes = np.array([i for i in range(self.len)])\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        if self.shuffle:\n",
    "            ridxes = self.idxes\n",
    "            np.random.shuffle(ridxes)\n",
    "            self.X = self.X[ridxes]\n",
    "            if self.y is not None:\n",
    "                self.y = self.y[ridxes]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.i >= self.len:\n",
    "            raise StopIteration\n",
    "\n",
    "        X = torch.FloatTensor(self.X[self.i:self.i + self.batch_size, :])\n",
    "    \n",
    "        if self.y is not None:\n",
    "       \n",
    "            y = torch.FloatTensor(self.y[self.i:self.i + self.batch_size])\n",
    "     \n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "\n",
    "        batch = (X, y) \n",
    "        self.i += self.batch_size\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch dataloader \n",
    "train_loader = Loader(X_train, y_train)\n",
    "val_loader = Loader(X_val, y_val)\n",
    "test_loader = Loader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)  \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.out = nn.Linear(hidden_size2, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size=n_input,\n",
    "                  hidden_size1=n_hidden1,\n",
    "                  hidden_size2=n_hidden2,\n",
    "                  num_classes=n_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [2/4], Loss: 0.0015\n",
      "Epoch [1/20], Step [4/4], Loss: 0.0000\n",
      "Epoch [2/20], Step [2/4], Loss: 0.0073\n",
      "Epoch [2/20], Step [4/4], Loss: 0.0001\n",
      "Epoch [3/20], Step [2/4], Loss: 0.0281\n",
      "Epoch [3/20], Step [4/4], Loss: 0.0000\n",
      "Epoch [4/20], Step [2/4], Loss: 0.0000\n",
      "Epoch [4/20], Step [4/4], Loss: 0.0006\n",
      "Epoch [5/20], Step [2/4], Loss: 0.0004\n",
      "Epoch [5/20], Step [4/4], Loss: 0.0002\n",
      "Epoch [6/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [6/20], Step [4/4], Loss: 0.0001\n",
      "Epoch [7/20], Step [2/4], Loss: 0.0000\n",
      "Epoch [7/20], Step [4/4], Loss: 0.0021\n",
      "Epoch [8/20], Step [2/4], Loss: 0.0002\n",
      "Epoch [8/20], Step [4/4], Loss: 0.0000\n",
      "Epoch [9/20], Step [2/4], Loss: 0.0004\n",
      "Epoch [9/20], Step [4/4], Loss: 0.0001\n",
      "Epoch [10/20], Step [2/4], Loss: 0.0002\n",
      "Epoch [10/20], Step [4/4], Loss: 0.0001\n",
      "Epoch [11/20], Step [2/4], Loss: 0.0000\n",
      "Epoch [11/20], Step [4/4], Loss: 0.0003\n",
      "Epoch [12/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [12/20], Step [4/4], Loss: 0.0003\n",
      "Epoch [13/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [13/20], Step [4/4], Loss: 0.0000\n",
      "Epoch [14/20], Step [2/4], Loss: 0.0000\n",
      "Epoch [14/20], Step [4/4], Loss: 0.0000\n",
      "Epoch [15/20], Step [2/4], Loss: 0.0000\n",
      "Epoch [15/20], Step [4/4], Loss: 0.0000\n",
      "Epoch [16/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [16/20], Step [4/4], Loss: 0.0001\n",
      "Epoch [17/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [17/20], Step [4/4], Loss: 0.0001\n",
      "Epoch [18/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [18/20], Step [4/4], Loss: 0.0000\n",
      "Epoch [19/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [19/20], Step [4/4], Loss: 0.0000\n",
      "Epoch [20/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [20/20], Step [4/4], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logit = model(x)\n",
    "        loss = criterion(logit, y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "preds = []\n",
    "for i, (x, y) in enumerate(val_loader):  \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logit = model(x)\n",
    "    y_true.append(y)\n",
    "    preds.append(logit.sigmoid())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat(preds, axis=0).detach().cpu().numpy()\n",
    "y_true = torch.cat(y_true, axis=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, np.where(preds>=0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = []\n",
    "preds = []\n",
    "for i, (x, y) in enumerate(test_loader):  \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logit = model(x)\n",
    "    y_true.append(y)\n",
    "    preds.append(logit.sigmoid())\n",
    "\n",
    "preds = torch.cat(preds, axis=0).detach().cpu().numpy()\n",
    "y_true = torch.cat(y_true, axis=0).detach().cpu().numpy()\n",
    "accuracy_score(y_true, np.where(preds>=0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi classification: Iris Dataset on Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "\n",
    "#Condition extraction from data frame\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X).astype(np.float32)\n",
    "\n",
    "# Convert label to number\n",
    "y[y == \"Iris-setosa\"] = 0\n",
    "y[y == \"Iris-versicolor\"] = 1\n",
    "y[y == \"Iris-virginica\"] = 2\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=4, out_features=50, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (out): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNet(input_size=n_input,\n",
    "                  hidden_size1=n_hidden1,\n",
    "                  hidden_size2=n_hidden2,\n",
    "                  num_classes=n_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch dataloader \n",
    "train_loader = Loader(X_train, y_train)\n",
    "val_loader = Loader(X_val, y_val)\n",
    "test_loader = Loader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [2/6], Loss: 0.0161\n",
      "Epoch [1/20], Step [4/6], Loss: 0.0704\n",
      "Epoch [1/20], Step [6/6], Loss: 0.1022\n",
      "Epoch [2/20], Step [2/6], Loss: 0.0002\n",
      "Epoch [2/20], Step [4/6], Loss: 0.0002\n",
      "Epoch [2/20], Step [6/6], Loss: 0.0007\n",
      "Epoch [3/20], Step [2/6], Loss: 0.0624\n",
      "Epoch [3/20], Step [4/6], Loss: 0.0010\n",
      "Epoch [3/20], Step [6/6], Loss: 0.1367\n",
      "Epoch [4/20], Step [2/6], Loss: 0.0112\n",
      "Epoch [4/20], Step [4/6], Loss: 0.0192\n",
      "Epoch [4/20], Step [6/6], Loss: 0.0263\n",
      "Epoch [5/20], Step [2/6], Loss: 0.0002\n",
      "Epoch [5/20], Step [4/6], Loss: 0.0009\n",
      "Epoch [5/20], Step [6/6], Loss: 0.0551\n",
      "Epoch [6/20], Step [2/6], Loss: 0.0258\n",
      "Epoch [6/20], Step [4/6], Loss: 0.0023\n",
      "Epoch [6/20], Step [6/6], Loss: 0.0222\n",
      "Epoch [7/20], Step [2/6], Loss: 0.0286\n",
      "Epoch [7/20], Step [4/6], Loss: 0.0002\n",
      "Epoch [7/20], Step [6/6], Loss: 0.0492\n",
      "Epoch [8/20], Step [2/6], Loss: 0.0060\n",
      "Epoch [8/20], Step [4/6], Loss: 0.0001\n",
      "Epoch [8/20], Step [6/6], Loss: 0.0089\n",
      "Epoch [9/20], Step [2/6], Loss: 0.0016\n",
      "Epoch [9/20], Step [4/6], Loss: 0.0187\n",
      "Epoch [9/20], Step [6/6], Loss: 0.0869\n",
      "Epoch [10/20], Step [2/6], Loss: 0.0142\n",
      "Epoch [10/20], Step [4/6], Loss: 0.0002\n",
      "Epoch [10/20], Step [6/6], Loss: 0.0038\n",
      "Epoch [11/20], Step [2/6], Loss: 0.0057\n",
      "Epoch [11/20], Step [4/6], Loss: 0.0005\n",
      "Epoch [11/20], Step [6/6], Loss: 0.1015\n",
      "Epoch [12/20], Step [2/6], Loss: 0.0001\n",
      "Epoch [12/20], Step [4/6], Loss: 0.0087\n",
      "Epoch [12/20], Step [6/6], Loss: 0.0462\n",
      "Epoch [13/20], Step [2/6], Loss: 0.0001\n",
      "Epoch [13/20], Step [4/6], Loss: 0.0035\n",
      "Epoch [13/20], Step [6/6], Loss: 0.0256\n",
      "Epoch [14/20], Step [2/6], Loss: 0.0027\n",
      "Epoch [14/20], Step [4/6], Loss: 0.0054\n",
      "Epoch [14/20], Step [6/6], Loss: 0.0202\n",
      "Epoch [15/20], Step [2/6], Loss: 0.0003\n",
      "Epoch [15/20], Step [4/6], Loss: 0.0001\n",
      "Epoch [15/20], Step [6/6], Loss: 0.0024\n",
      "Epoch [16/20], Step [2/6], Loss: 0.0076\n",
      "Epoch [16/20], Step [4/6], Loss: 0.0076\n",
      "Epoch [16/20], Step [6/6], Loss: 0.0000\n",
      "Epoch [17/20], Step [2/6], Loss: 0.0126\n",
      "Epoch [17/20], Step [4/6], Loss: 0.0005\n",
      "Epoch [17/20], Step [6/6], Loss: 0.0022\n",
      "Epoch [18/20], Step [2/6], Loss: 0.0001\n",
      "Epoch [18/20], Step [4/6], Loss: 0.0021\n",
      "Epoch [18/20], Step [6/6], Loss: 0.0074\n",
      "Epoch [19/20], Step [2/6], Loss: 0.0001\n",
      "Epoch [19/20], Step [4/6], Loss: 0.0037\n",
      "Epoch [19/20], Step [6/6], Loss: 0.0060\n",
      "Epoch [20/20], Step [2/6], Loss: 0.0002\n",
      "Epoch [20/20], Step [4/6], Loss: 0.0004\n",
      "Epoch [20/20], Step [6/6], Loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logit = model(x)\n",
    "        loss = criterion(logit, y.long())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = []\n",
    "preds = []\n",
    "for i, (x, y) in enumerate(test_loader):  \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logit = model(x)\n",
    "    y_true.append(y)\n",
    "    _, predicted = torch.max(logit.data, 1)\n",
    "    preds.append(predicted)\n",
    "\n",
    "preds = torch.cat(preds, axis=0).detach().cpu().numpy()\n",
    "y_true = torch.cat(y_true, axis=0).detach().cpu().numpy()\n",
    "accuracy_score(y_true, np.where(preds>=0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST TASK\n",
    "\n",
    "SOURCE: https://github.com/lhagiimn/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
